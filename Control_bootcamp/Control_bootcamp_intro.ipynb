{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8cfbbfc-4f16-43b9-80ef-4fed61ca4027",
   "metadata": {},
   "source": [
    "##\n",
    "\n",
    "### Control bootcamp overview\n",
    "Contents:\n",
    "    Highlights of modern control theory\n",
    "    design controllers\n",
    "    design sensors (Kalman filters)\n",
    "    major types of optimal control theory\n",
    "    what is easy and hard in control theory\n",
    "    \n",
    "Dynamical systems analysis has been a great way at describing/predicting the evolution of the system. Optimal control builds on dynamical system analysis by allowing for interventions. \n",
    "\n",
    "*Dyanmical systems*: \n",
    "$\\dot{x} = Ax$\n",
    "\n",
    "*Control systems*: \n",
    "$\\dot{x} = Ax + Bu$\n",
    "\n",
    "#### Types of control: \n",
    "Passive control - designed into system upfront/doesn't consume energy\n",
    "Active control - consumes energy\n",
    "    Open loop - preplanned control law, always putting in energy through input signal $u_t$\n",
    "    Closed loop - generally, lower energy than open loop, input signal takes feedback from output signal\n",
    "    \n",
    "*Why feedback (closed loop) over open loop control?*\n",
    "*Uncertainty:* Endogenous system uncertainty in physics model. Allows to deal with uncertainty, an enemy of open loop control. If system deviates from model of system, control laws can adapt. \n",
    "*Instability:* feedback can overcome in instabilities (changes eigenvalues of system), i.e. create new stable points.\n",
    "*Disturbances:* exogenous uncertainties i.e. guest of wind.\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d059f664-c2f6-441b-b0f5-e8461f2862ad",
   "metadata": {},
   "source": [
    "### Nomenclature\n",
    "$u_t$ - Input signal\n",
    "$B$ - input actuation matrix\n",
    "\n",
    "$\\dot{x} = Ax$ - A continous-time linear dynamical system\n",
    "\n",
    "$X_{t+1} = A^{t} X_0$- A discrete-time linear dynamical system\n",
    "\n",
    "Rank deficient - not full column rank\n",
    "\n",
    "Controllability Gramian - magnitude of controllability a system has. Usually calculated by an SVD approach to on 'rank deficiency' calculation matrix. \n",
    "\n",
    "*Stability* - A system is said to be *stabilisable* if all of the unstable eigenvectors of A are in controllable subspace. I.e. you may not be able to control all of $\\mathbb{R^n}$ however if all uncontrollable directions have negative eigenvalues (are therefore stable) then system is *stabilisable*.\n",
    "\n",
    "*Reachability* - refers to whether a state can be reached given *controllability*. \n",
    "\n",
    "*Observability* - given system $\\dot{x} = Ax + Bu$, observability is the part of state X that is observable (can obtain data for) such that $y = Cx$. \n",
    "\n",
    "*Estimator* - an estimator is used to estimate the full state x. An example is the Kalman filter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c060aa-bf39-4393-a21f-e336ad94912a",
   "metadata": {},
   "source": [
    "### Linear systems (video 2)\n",
    "\n",
    "https://www.youtube.com/watch?v=nyqJJdhReiA&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=2\n",
    "\n",
    "How to analyse and solve linear system\n",
    "HOw to linearise a system and find fixed points\n",
    "What do eigenvalues mean for system\n",
    "\n",
    "The crux of this video is about reducing the complexity of the dynamical system $\\dot{x} = Ax$, through transforming to a *more simple* (linearly independent) eigenvector coordinate system.\n",
    "For what types of systems can we control for; include tests\n",
    "1. Start with linear system; need to solve for $dot{x} = Ax$ but involves exponential of matrix. \n",
    "2. Transfrom into eigenvector coordinates of A. \n",
    "2. Solve differential equations in eigenvector coordinates.\n",
    "3. Taylor series of $e^{At} = T e^{Dt} T^{-1}$, proof below.\\\n",
    "4. Plug eigenvector solution back into *real physical* coordinates, x, $X(t) = Te^{Dt}T^{-1}X(0)$\n",
    "\n",
    "\n",
    "Cornerstone of lecture for controls. \n",
    "$$\\dot{x} = Ax$$\n",
    "Which has solution: \n",
    "$$x(t) = e^At x(0)$$\n",
    "\n",
    "But when A is a matrix how do we take the exponential? Answer; the Taylor series.\n",
    "\n",
    "$e^{At} = I + At + \\frac{A^2t^3}{2!} + \\frac{A^3t^3}{3!} +  ....$\n",
    "\n",
    "The above can be decomposed into eigenvalues and eigenvector coordiante system where $AT = TD \\rightarrow T^-1 A T = D$. Changing these coordinates makes the system easier to solve. Consider mapping to z coordinates where $$x = Tz$$ and $$\\dot{x} = T\\dot{z} = Ax = A Tz  \\rightarrow \\dot{z} = T^{-1} ATz = Dz$$. Where Z is in eigencoordinates (but why?) and D is the diagonal matrice of the eigenvalues which yields $$ \\dot{z} = Dz$$ The above system $ \\dot{z} = Dz$ is simple and known $z(t) = e^Dt z(0)$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Staibility and eigenvalues (video 3) \n",
    "https://www.youtube.com/watch?v=1YMTkELi3tE&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=4\n",
    "\n",
    "Stability is about analying what happens to the system do as time goes to infinity. The crux is anlaysing the eigenvalue matrix, D; if any of these eigenvalues are positive the system 'blows up' and diverges off to infinity. **The system is said to be unstable.** A big part of control theory is that deriving appropriate $u$ control actions to drive eigenvalues to be negative/stable. \n",
    "\n",
    "Generally in physiscs, the linear dynamical system is continuosly evolved. However in practice the system is measured in discrete time. A discrete time system can be modelled as $X_{k+1} = A x_k , x_k = x(\\Delta t)$. In discete time the notion of *stability* is slightly different. In discerte time, state at time t can be derived by simply evolving the system's matrix A, such that: \n",
    "$$ X_1 = A^1 X_0 $$\n",
    "$$ X_2 = A^2 X_0 $$\n",
    "\n",
    "$$ X_N = A^N X_0 $$\n",
    "\n",
    "\n",
    "\n",
    "### Lienarizing Around a Fixed Point (video 4)\n",
    "https://www.youtube.com/watch?v=1YMTkELi3tE&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=4\n",
    "\n",
    "Previous videos have dely with the linear dynamical systems in continuous time. For a non-linear applicatinon, instead of $ \\dot{x} = Ax$, the non-linear form is $\\dot{x} = f(x)$ where $f(x)$ is non-linear but assumed to have fixed points.\n",
    "Fixed point is where the system is stablae and doesn't move i.e. the vertical top or bottom of a pendulum. Albeit, this fixed point is an unstable fixed point as any deviation from this position will cause the system to move away from fixed point.\n",
    "\n",
    "1. Find fixed points such that $f(\\bar{x}) = 0$\n",
    "2. Linearise around x using Jacobian (by taking the partial derivatives of f) \n",
    "\n",
    "i.e. for dynamical system: \n",
    "$$ \\dot{x_1} = f_1(x_1, x_2) = x_1 x_2$$\n",
    "$$ \\dot{x_2} = f_2(x_1, x_2) = x^2_1 + x^2_2$$\n",
    "\n",
    "then:\n",
    "$$ \\frac{Df}{Dx} = \\begin{bmatrix} x_2 & x_1 \\\\ 2x_1 & 2x_2 \\end{bmatrix}$$ \n",
    "\n",
    "\n",
    "Around a fixed point for $\\dot{x} = f(x)$, on a local neighbourhood, expand $f(\\bar{x})$ using a Taylor series. Results in, $ \\dot{x}  = f(\\bar{x}) + \\frac{Df}{Dx}_{\\bar{x}}((x-\\bar{x}) + \\frac{D^2f}{Dx^2}_{\\bar{x}}(x-\\bar{x})^2  $. However, any term above the first order is assumed to be zero. The left over dynamics result in the linearisation of x which yields $\\Delta \\dot{x} = \\frac{Df}{Dx}_{\\bar{x}} \\Delta X \\rightarrow \\Delta \\dot{x} = A \\Delta x$\n",
    "\n",
    "\n",
    "\n",
    "#### Pendulum example\n",
    "Is a ture nonlinear system which has two fixed points and following equations. \n",
    "\n",
    "1. Find state space \n",
    "$\\ddot{\\theta} = -\\frac{g}{L}sin(\\theta)$ which has the following state space equation **Inert image**\n",
    "\n",
    "Then find the fixed points of the state space solution\n",
    "\n",
    "2. Find Jacobian\n",
    "Find matrix of partial differential equations of the system. Substitute in fixed points to Jacobian. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3549ad2e-6c70-4ed0-90da-da7bb96ccc92",
   "metadata": {},
   "source": [
    "### Controlability (video 5)\n",
    "Until this point focus has been on $\\dot{x} = Ax$ absent of $Bu$. A's eigenvalue's were studied to identify which dynamical systems were stable and which weren't. Now control feedback is added to the system, called *controlability*. \n",
    "Starting with $\\dot{x} = Ax - BKx$, where K is the proportionality of feedback control K.\n",
    "\n",
    "What determines if a system is controlable? \n",
    "\n",
    "In industry control problesms the A (dynammical system is fixed) and B (control dynamics)matrices are fixed; only $u$ is controlable.\n",
    "\n",
    "Note: for some complex systems, small number of coupled actuators can control the system. How can we determine if a system can be controled? \n",
    "\n",
    "IFF rank(C) = n then system is controllable, given C = \\[B, AB, A^2B, A^3B, ... , A^{n-1}B\\] (note: A and B are from the control system equation  $\\dot{x} = Ax - BKx$ and n is the dimension of the X. \n",
    "This rule is a binary outcome to determine whether a system is controllable or not. To quantify the amount of controllability of the system, the Singular Value Decomposition of C is taken. The order of the Singular Values is the order in which it the system is easiest to control. \n",
    "\n",
    "\n",
    "### Controlability Reachability, Eigenvalue Placement (video 6)\n",
    "Reintroduces the *rank deficiency* condition about matrix C, = \\[B, AB, A^2B, A^3B, ... , A^{n-1}B\\] where rank(C) = n where $X \\in \\mathbb{R^n}$\n",
    "\n",
    "Lecture introduces 3 equivalences; \n",
    "1. System is controlable\n",
    "2. Arbitrary eigenvalue (pole) placement where $u = -kX \\rightarrow \\dot{x} = (A -Bk)X$ \n",
    "3. Reachability (full in $\\mathbb{R^n}$  - Reachable set $R_t = { \\eta \\in \\mathbb{R^n} | there is an input u(t) so that x(t) = \\eta}$. More precisely, $R_t \\in \\mathbb{R^n}$\n",
    "\n",
    "## Controlability and Discrete-Time Impulse Response (video 7)\n",
    "https://www.youtube.com/watch?v=tnsWsMwYbEU&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=7\n",
    "\n",
    "Why is the rank deficiency of C sufficient for determining controllability of a system? To give an intuition as to sufficiency consider an *impulse response  in u* at time = 0 for discrete dynamical system $x_{k+1} = Ax_k + Bu_k$ with X(0) = 0 and impulse response u(0) = 1 and u(t) = 0 for t > 0. The below matrix shows how an impulse is propagated through the state space of a solution. The C matrix are these column vectors stacked as columns. The idea being if this stacked matrix is not full rank then variables exist in state stapce, X, such that the control impulse u cannot influence them.\n",
    "\n",
    "$$\\begin{matrix} \n",
    "u_0 = 1 & X_0 = 0 \\\\\n",
    "u_1 = 0 & X_1 = B \\\\\n",
    "u_2 = 0 & X_2 = AB \\\\\n",
    "u_3 = 0 & X_3 = A^2B \\\\\n",
    "... & ... \\\\\n",
    "u_n = 0 & X_n = A^{n-1}B \\\\\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "\n",
    "## Degrees of Controllability and Gramians (video 8)\n",
    "https://www.youtube.com/watch?v=ZNHx62HbKNA&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=8\n",
    "\n",
    "Previously had a binary rule for whether a systme is controllable. Each system has a degree of which it can be controlled; referred to as the *Controllability Gramian*. Eigenvectors of the Gramian matrix have the most amount of controllability, i.e. given a input signal of fixed magnitude, the directions with the largest eigenvalues are affected most. i.e. the Eienvectors/values of Gramian is how far you can get in controllability of a unit input of control. \n",
    "\n",
    "A system dynamical system *with control* yields $X(t) = e^{At} X(0) + \\int_0^te^{A(t - \\tau) B u(\\tau) d \\tau$ where the Gramian (controllability) is given as  $W_t =  \\int_0^te^{At}BB^Te^{A^tt}d \\tau \\in \\mathbb{R^{nxn}}$. IN subsequenet lectures the *Gramian matrix* will be derived; however, Gramian can also be thought of as the *controllability matrix* squared. Taking the SVD of C, SVD(C) ranks the magnitudes of direction of each eigenvector. \n",
    "\n",
    "A system is said to be *stabilisable* if all of the unstable eigenvectors of A are in controllable subspace. I.e. you may not be able to control all of $\\mathbb{R^n}$ however if all uncontrollable directions have negative eigenvalues (are therefore stable) then system is *stabilisable*.\n",
    "\n",
    "\n",
    "## Controllabilty and the PBH Test (video 9): \n",
    "https://www.youtube.com/watch?v=PrfxmkBsYKE&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=9\n",
    "The Popov-Belevitch-Hautus (PBH) test is another test for controllability which is favourable compared to previous rank deficiency tests of C as requires less compute. PBH test assesses if (A, B) is controllable be computing: \n",
    "$$ rank([(A - \\lambda I) B]) = n \\quad \\forall  \\lambda \\in \\mathbb{C}$$\n",
    "\n",
    "There are three criteria to determine $ rank([(A - \\lambda I) B]) = n$ \n",
    "1. When $\\lambda$ is not the eigenvalues then rank (A - \\lambda I) = n since determinant $\\ne$ 0\n",
    "2. B needs to have some component in each eigenvector direction. \n",
    "3. If B is a random vector, then (A,B) will be cotnrollable with high probability. \n",
    "\n",
    "Note: when $rank([(A - \\lambda I) B]) = n$ has m repeated eigenvalues then B must be m dimensions. \n",
    "\n",
    "## Cayley-Hamilton Theorem (video 10): \n",
    "https://www.youtube.com/watch?v=PrfxmkBsYKE&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=10\n",
    "Every matrix A satisfies its own characteristic (eigenvalue) equation. This is important for equivalence for *controlability* and *reachability* which is built on the *Cayley-Hamilton* theorem which states:\n",
    "$$det(A-\\lambda I) = 0 $$\n",
    "$$ \\lambda ^n + a_{n-1} \\lambda ^{n-1} + ... + a_2 \\lambda ^2 + a_1 \\lambda  + a_0 = 0$$\n",
    "and since A satisfies its own characteristic equation, then: \n",
    "$$ A ^n + a_{n-1} A ^{n-1} + ... + a_2 A ^2 + a_1 A  + a_0 = 0 $$\n",
    "$$ A ^n  = a_{n-1} A ^{n-1} + ... + a_2 A ^2 + a_1 A  + a_0 = 0 $$\n",
    "\n",
    "This means $e^{At} = \\phi_0(t)I + \\phi_1(t)A + ... + \\phi_n(t)A^{n-1}$.\n",
    "\n",
    "## Controlabiliy and Reachable with Cayley-Hamilton (video 11)\n",
    "Goal: show that with *controlability*, any state is *reachable*. Note if state, $\\xi \\in \\mathbb{^n}$, is reachable, then $\\xi = \\int^t_0 e^{A(t-\\tau)}Bu(\\tau)d\\tau$ for some $u(\\t)$. Then using the Cayley-Hamilton theorem, the complicated convolution can be avoided to put into form: \n",
    "$$\\xi = \\int^t_0 (\\phi_0(t-\\tau)u(\\tau)IB + \\phi_1(t-\\tau)u(t)AB + ... + \\phi_n-1(t-\\tau)u(t)A^{n-1}B)d\\tau$$\n",
    "$$\\xi = B \\int^t_0 (\\phi_0(t-\\tau)u(\\tau)d\\tau + AB\\int^t_0 \\phi_1(t-\\tau)u(t)d\\tau + ... + A^{n-1}B\\int^t_0\\phi_n-1(t-\\tau)u(t))d\\tau$$\n",
    "\n",
    "$$\n",
    "\\xi =\n",
    "\\begin{bmatrix} \n",
    "B & AB & ... & A^{n-1}B\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} \n",
    "\\int^t_0 (\\phi_0(t-\\tau)u(\\tau)d\\tau \\\\\n",
    "\\int^t_0 \\phi_1(t-\\tau)u(t)d\\tau \\\\\n",
    "... \\\\\n",
    "\\int^t_0\\phi_n-1(t-\\tau)u(t))d\\tau\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "From the *linearisation* of the system by application of Cayley-Hamilton theorem it can be shown that the transformation spans $\\mathbb{R^n}$. Note: there is no unique u(t) that will yield a given state, as there are infinite number of ways to reach given state $\\xi$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c02416-c598-4403-bb7b-0052fba8ab3b",
   "metadata": {},
   "source": [
    "## Inverted pendulum on a cart (video 12)\n",
    "Dynamical system is non-linear and has following characteristics:\n",
    "$$ \\bar{x} = \\begin{bmatrix} x \\\\ \\dot{x} \\\\ \\theta \\\\ \\dot{\\theta} \\end{bmatrix}$$\n",
    "\n",
    "The system has two fixed points; $(free, 0, 0, 0) or (free, 0,\\pi, 0)$ for downward and upward fixed points respectively. Each point is then linearised.\n",
    "\n",
    "*Desigining a controller*. Code is presented which covers; \n",
    "1. Compute eigenvalues of A to identify stable points.\n",
    "2. Determine rank of matrix to determine *controlability*. \n",
    "3. Set values of prortional controller K such that eigenvalues of $(A-B*K)$ are stable and equal to eigenvalue vector defined (i.e. all negative). Note there is sweet spot, such that the eigenvalues reach a solution fast but not so fast that the control breaks. This optimal trade off is solved through application of Linear Quadratic Regulators which balance how fast you get to a stable state vs the control energy it takes to get there.\n",
    "\n",
    "### Linear Quadratic Regulator Control for the Inverted Pendulum on a Cart (video 13)\n",
    "Previously, eigenvalues for the (A-BK) matrix used for feedback was guessed. However, given a certain cost function, an optimal set of eigenvalues exists. Linear Quadratic Regulation is a method to calculate this optima. Given, the objective function: \n",
    "$$ J = \\int_0^\\infty (x^TQx + u^TRu)dt$$\n",
    "\n",
    "LQR refers to:\n",
    "- Linear - linear in feedback of K \n",
    "- Quadratic - quadratic in cost function\n",
    "- Regulator - means will stabilise system\n",
    "\n",
    "### Motivation for Full-State Estimation (video 15)\n",
    "https://www.youtube.com/watch?v=LTNMf8X21cY&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=15<br>\n",
    "With LQR full control of the system was available, however, in real life full state isn't alway accessible. Given a dynamical system, $\\dot{x} = Ax + Bu, \\quad x \\in \\mathbb{R^n}$, the observability of a system is given by $y = Cx, \\quad y \\in \\mathbb{R^p}$ sucht that p << n. Whereas *controlability* is steering towards state, *observability* is can I *observe* state X from measurement $y(t)$. Since for control, not all states are always available and an *observer* can be created.\n",
    "\n",
    "### Observability (video 16)\n",
    "https://www.youtube.com/watch?v=LTNMf8X21cY&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=16 <br>\n",
    "An estimator is used to estimate the full state x. An example is the Kalman filter. Observability and controlability have the same linear algebra i.e. the same rank tests apply. Mathematically, they are the same problem Gramians apply etc.\n",
    "\n",
    "### Full State Estimation (video 17)\n",
    "https://www.youtube.com/watch?v=MZJMi-6_4UU&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=17 <br>\n",
    "\n",
    "Observability, has the same linear algebra as controlabiity. Controlabiliyt meant can I steer a system anywhere given some u, whereas observability means can I estimate any state x from measurements of y(t). \n",
    "The Kalman filter is a method to derive full state estimations, required for input into Linear Quadratic Controllers. Starting with the dynamical system: \n",
    "$$ \\dot{x} = Ax + Bu $$\n",
    "$$ y = Cx$$ \n",
    "Then the estimator for the full states, the *Kalman filter*, is a dynamical system in itself such that $\\hat{x} = f(u,y)$. Then the estimate $\\frac{d}{dt}\\hat{x} = A \\hat{x} + Bu + K_f(y - \\hat{y})$ given that $\\hat{y} = C\\hat{x}$. Rearranging $\\frac{d}{dt}\\hat{x}$ yields: \n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{d}{dt}\\hat{x} &= A\\hat{x} + Bu + K_fy - K_fC\\hat{x} \\\\\n",
    "&= (A - K_fC)\\hat{x} + \\begin{bmatrix} B & K_f \\end{bmatrix}\\begin{bmatrix} u \\\\ y \\end{bmatrix}\n",
    "\\end{align}\n",
    "$$ \n",
    "The addition of the $K_f(y-\\hat{y})$ term is to account for the difference between how the system was predicted to act vs how it actually did act and corrects the estimate. \n",
    "\n",
    "Finally, the full state estimate error, $epsilon = x - \\hat{x}$ that has the following dynamical system for error. \n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{d}{dt}\\epsilon &= \\frac{d}{dt}x - \\frac{d}{dt}\\hat{x} = Ax + Bu - A\\hat{x} + K_fC\\hat{x} - K_fy  - Bu \\\\\n",
    "&= A(x-\\hat{x}) - K_fC(x - \\hat{x}) \\quad \\text{since 'Bu's cancel out} \\\\\n",
    "&= (A - K_fC)\\epsilon \\\\ \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Note: the eigenvalues of $(A -K_fC)$ are changed by the filter gains to reach observability.\n",
    "\n",
    "In the last equation, if observable than place eigenvalues by choosing optimal K.\n",
    "![](video_17.PNG)\n",
    "\n",
    "### Kalman Filters (video 18)\n",
    "https://www.youtube.com/watch?v=LTNMf8X21cY&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=17 <br>\n",
    "\n",
    "Kalman filter has components: \n",
    "- $W_d$ - Gaussian (system disturbance) with zero mean and defined variance, $V_d$.\n",
    "- $V_d$ - Variance\n",
    "- $W_n$ - Gaussian (measurement noise) with zero mean and defined variance, $V_n$.\n",
    "- $V_n$ - Variance\n",
    "\n",
    "such that: \n",
    "$$ \\dot{x} = Ax + Bu + w_d$$\n",
    "$$ y = Cx + w_n$$ \n",
    "\n",
    "The Kalman filter balances $\\dot{x} = (A-k_fC)\\epsilon$ and optimises $J = E((x - \\hat{x})^T(x-\\hat{x}))$ given the estimates for $W_d$ and $W_n$. \n",
    "\n",
    "### Observability in Example (video 19)\n",
    "https://www.youtube.com/watch?v=XBI_hQRqMvM&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=19 <br>\n",
    "Previously have looked at dynamical system of equations $$ \\dot{x} = Ax + Bu + w_d$$ $$ y = Cx + w_n$$ then testing observability matrix (A,C) and check for rank deficiency. The most popular method for full state estimation is the *Kalman filter*. Applying observabilty to the cart problem, start with hypothesis that $\\begin{bmatrix} 1 & 0 & 0 & 0 \\end{bmatrix}$ is enough for observability. Remember, that observabilty matrix is  $\\begin{bmatrix} C \\\\ CA \\\\ CA^2 \\\\ CA^3 \\end{bmatrix}$ which is full rank. \n",
    "\n",
    "### Observability Example - Part 2 (video 20)\n",
    "https://www.youtube.com/watch?v=DLytfA10RR8&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=20 <br>\n",
    "What about if the cart position, x, is not important (translational invariant) can an obvervable system be found? IF X is removed than the matrix (A,C) becomes observable which informs that all variables $\\dot{x}, \\, \\theta \\, \\& \\, \\dot{\\theta}$ are dependent and can be backed out from a single observation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cb8778-727b-43a8-90ab-12e8aa80bd92",
   "metadata": {},
   "source": [
    "### Kalman Filter Example (video 21)\n",
    "https://www.youtube.com/watch?v=Lgq4R-F8SX8&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=21 <br>\n",
    "Focus in this lecture is continued on the cart pole problem and then further focuses on fixed point in the downward position. First, implement Kalman filter to derive estimate of the full states, $\\hat{x}$ to overcome observability problem. The balance between variance in the system $V_d$ and measurement $V_n$ which are tuning knobs and tells us how the Kalman filter is going balance the model of the system against the measurements.\n",
    "\n",
    "There are a multiple ways to build a Kalman filter; note the LQE equation can solve the Kalman filter however so can the LQR if matrices are transposed.\n",
    "\n",
    "1. An example would create *true simulated data* from a deterministic model dyanmical systems model; \n",
    "2. then create a Kalman filter for deterministic system. \n",
    "3. Inject noise to the *true simulated data* (which uses the system's true dynamics) to form *simulated + noise* data\n",
    "4. Run state estimation on *simulated + noise* data\n",
    "5. Plot resulting outputs for all variables in state.\n",
    "\n",
    "\n",
    "### Linear Quadratic Gaussian (video 22)\n",
    "https://www.youtube.com/watch?v=H4_hFazBGxU&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=22 <br>\n",
    "Combining the LQR and LQE = Linear Quadratic Gaussian such that the optimal LQR and LQE separately optimised additively equal the LQG, which is referred to as the *separation principle*. LQG's may not be robust to noise.\n",
    "\n",
    "\n",
    "### LQG in Matlab (video 23) \n",
    "https://www.youtube.com/watch?v=reRT8LbPhBs&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=23 <br>\n",
    "First half of lecture talks through the LQR implementation of the cart problem in Matlab. Second half includes use of the Kalman filter (combined with LQR) to do feedback control based on only cart's state position."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00acd0c6-7a16-4d42-9afc-b7be25aa8990",
   "metadata": {},
   "source": [
    "### Introduction to robust control (video 24)\n",
    "https://www.youtube.com/watch?v=Y6MRgg_TGy0&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=24 <br>\n",
    "Robust cotnrol doesn't guarantee that optimal control will not blow up in the presence of uncertainty. One of the most important papers in control, from John Doyle, Guaranteed Stability Margins for LQG Regulators. The paper describes the effect of uncertainty on the full state space estimation an impacts on system uncertainty. In following lectures examples are given to show that a LQG regulator may be performant but not robust to uncertainty. HOw to tell if a system is robust, what robust means and how to design system to have high performance and be robust. Will also cover *transfer fucntions* *frequency domains* two important concepts for robustness analysis.\n",
    "\n",
    "### Equivalent representations of Linear Systems (video 25)\n",
    "https://www.youtube.com/watch?v=HasvumXl_vE&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=25 <br>\n",
    "\n",
    "Divervsion fromt ordinary differential equations to Laplace transforms and transfer functions.\n",
    "\n",
    "For transfer functions there are 3 representations for linear systems:\n",
    "1. State space domain, \n",
    "$$ \\dot{x} = Ax + Bu$$\n",
    "$$ y = Cx$$\n",
    "\n",
    "2. Frequency  domain (Transfer function), if a sin wave is input to a system a sin wave should also be output only with changes to magnitude and phase.\n",
    "$$G(s) = C(sT-A)^{-1}B$$\n",
    "\n",
    "3. Time domain (impulse response)\n",
    "$$ y(t) = \\int^t_0 h(t - \\tau)u(t)dt $$\n",
    "\n",
    "Either of above 3 representations for linear systems have benefits for use. Transfer functions are provide a methodology to assess robustness of controls.\n",
    "\n",
    "What is the idea of a transfer function;  if a sin wave is input to a system a sin wave should also be output only with changes to magnitude and phase. More precisely, if $sin(\\omega t)$ is input to a system then $Asin(\\omega t + \\phi)$. Transfer functions help understand the robustness of a system.\n",
    "\n",
    "### Example Frequency Response (Bode Plot) for Spring-Mass-Damper (video 26)\n",
    "https://www.youtube.com/watch?v=e-8y4MTT7NQ&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=26 <br>\n",
    "The *transfer function* (G) of a system can be thought of the Laplace transform of a system. First, recall that $L\\{\\frac{d}{dt}x = s \\bar{X}(s)$ and $L\\{\\frac{d^2}{dt@}x = s^2 \\bar{X}(s)$, by taking the Laplace transform differential terms are removed and system in turn becomes *algebraic*. As an example of the application of transfer functions, assume a system with inputs u and output x such that\n",
    "$$\\ddot{x} + \\dot{x} + x = u$$ \n",
    "then, take Laplace transform of both sides:\n",
    "$$s^2\\bar{X}(s) + s\\bar{X}(s) + \\bar{X}(s) = \\bar{u}(s)$$\n",
    "simplify, into characteristic equation: \n",
    "$$(s^2 + s + 1)\\bar{X}(s) = \\bar{u}(s)$$\n",
    "Finally the output *transfer function* is $\\frac{\\bar{x}}{\\bar{u}}$: which yields $\\frac{\\bar{x}}{\\bar{u}} = \\frac{1}{s^2 + s + 1}$.\n",
    "\n",
    "The Frequency response (Bode) plot helps idenitify resonate frequencies. All the information needed for a Bode plot can be derived from the *transfer function* G. An example with the phone on a spring cord illustrated teh 3 domains of outcomes; \n",
    "1. Small frequency magnitude for $\\omega$ input into $sin(\\omega t)$; yields output signal with same frequency signal. \n",
    "2. Medium frequency magnitude for $\\omega$ input into $sin(\\omega t)$; yields a *resonate frequency* output frequency signal.\n",
    "3. Very large frequency magnitude for $\\omega$ input into $sin(\\omega t)$; yields a zero output frequency signal.\n",
    "\n",
    "<font color='red'>TODO; add bode plots for second order systems with varied damping parameters</font>\n",
    "\n",
    "### Laplace Transforms and the Transfer Function (video 27)\n",
    "https://www.youtube.com/watch?v=0mnTByVKqLM&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=27 <br>\n",
    "Given a system with inputs u and outputs y, then the system tells us how frequency inputs $u$ and frequency of outpus via transfer function G(s), the frequency domain. For system the following holds $\\bar{Y}(s) = \\bar{G}(s)\\bar{U}(s)$ where $\\bar{\\cdot}(s)$ is the Laplace transform. \n",
    "\n",
    "The whole idea to Laplace transform the system: \n",
    "$$ \\dot{x} = Ax + Bu$$\n",
    "$$y=Cx$$ \n",
    "\n",
    "to yield\n",
    "$$ G(s) = C(sI - A)^{-1}B$$\n",
    "where $G(s)$ is derived from taking the Lpalace transform of the dyanmical system equations (assuming the initial conditions x(0) have died out from the system: \n",
    "$$ \\dot{x} = Ax + Bu \\rightarrow s\\bar{x}(s) = A\\bar{x}(s) + B\\bar{u}(s)  \\rightarrow (sI - A)\\bar{x}(s) = B\\bar{u}(s) \\rightarrow \\bar{x}(s) = (sI - A)^{-1}B\\bar{u}(s)$$\n",
    "$$y=Cx \\rightarrow \\bar{y}(s) = C\\bar{x}(s) \\rightarrow  \\bar{y}(s) = C(sI - A)^{-1}B\\bar{u}(s) \\rightarrow \\bar{y}(s) = G(s)\\bar{u}(s)$$ \n",
    "\n",
    "The transfer function avoids need to solve convolution integral to solve Y as a function of u, instead reduces solution to matrix multiplication. **THIS HELPS IDENTIFICATION AS TO WHETHER CONTROLLERS ARE ROBUST.**\n",
    "\n",
    "A Laplace transform allows for frequency analysis of functions which may blow up to infinity as is includes an exponential decay. Note: Laplace transform is defined as: \n",
    "$$L{x(t)} = \\int^\\infty_0 x(t)e^{-st}dt = \\bar{x}(s)$$\n",
    "\n",
    "\n",
    "### Benefits of Feedback on Cruise Control Example (video 28)\n",
    "https://www.youtube.com/watch?v=y4H03UOjlas&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=28 <br> \n",
    "Benefits of Feedback: \n",
    "- stability\n",
    "- uncertainty: included in dynamic model at measurement step, $V_d$ such i.e. $y=Cx+V_meas$\n",
    "- disturbance: included in dynamic model as system uncertainty $\\hat{x} = Ax + Bu + V_{dist}$\n",
    "\n",
    "When uncertainty and disturbances are present closed loop vastly outperforms open loop control.\n",
    "Til now have focues on stability of systems; focus is given to uncertainty and disturbance. Start with simple model for car, where y (speed) = u (accelarator input). For an open loop controller, if we wanted to get to r a constant input of u = r/2 would be applied. Closed loop functions are more appropriate given capacity to overcome uncertainty and disturbance.\n",
    "Illustrating a model which accounts for uncertainty, start with input controller (r-y) the difference between reference speed, r, and required output speed, y:\n",
    "$$u_{CL} = K \\epsilon = K(r-y)$$\n",
    "where r is the target, then output, y, yrields: \n",
    "$$ y_{CL} = Pu + d= PKr - PKy_{CL}  + d $$\n",
    "$$(1+PK)y_{CL} = PKr + d $$\n",
    "$$ y_{CL} = \\frac{PK}{1+PK} r + \\frac{1}{1+PK}d$$\n",
    "\n",
    "What the above mathmatically informs is that large K work as it will favour the targetting goal, r, instead of disturbances, d/ \n",
    "\n",
    "\n",
    "### Benefits of Feedback on Cruise Control Example (video 29)\n",
    "https://www.youtube.com/watch?v=-fNoz5K5FHA&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=29 <br>\n",
    "\n",
    "Video provides overview of cruise control example in MatLab; see below for Python solution. There is huge benefit from closed loop; if disturbances open loop will let them pass through without changing acceleration. In future integral functions will be added to system in stead of the proportional control hence (r-y) error in the feedback structure in video 28.\n",
    "\n",
    "\n",
    "### Cruise Control Example with Proportional-Integral (PI) control (video 30)\n",
    "https://www.youtube.com/watch?v=vxTJMGqjGdg&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=30 <br>\n",
    "Cuncertainty and disturbance is still going to be the focus. Previously, focus had been placed on *proportional* control i.e. the error betweent desired output, y, and input signal, r, multiplied by the term K. Vidoe 28 on cruise controla demonstrated this as input $u_{CL} = K \\epsilon = K(r-y)$. However, as shown in example, error reached a minimum but never completely reduced to zero. Inclusion of the integral term reduces steady state error to zero.\n",
    "\n",
    "A second innovation presented is time delay of response to propagate through the system i.e. Y won't jump instantaneously in resposne to u it will take an amount of time.\n",
    "\n",
    "#### Proportional + integral control\n",
    "An additional parameter $\\dot{z} = r - x$ is included to keep track of the integral term.\n",
    "$$u = K_P(r-y) + K_i\\int(r-y)dt$$\n",
    "then the dynamical system equations become\n",
    "$$ \\dot{z} = r -x $$\n",
    "$$ \\dot{x} -x - K_px + K_Iz - K_pr$$\n",
    "$$ u = K(_P(r-x) + K_Iz$$\n",
    "this becomes the following form of \n",
    "\n",
    "$$ \\frac{d}{dt} \\begin{bmatrix} x \\\\ z \\end{bmatrix}  = \\begin{bmatrix} -1 -K_p & K_I \\\\ -1 0 \\end{bmatrix}\\begin{bmatrix} x \\\\ z \\end{bmatrix} + \\begin{bmatrix} -K_p \\\\ 1 \\end{bmatrix}$$\n",
    "$$ y = \\begin{bmatrix} 1 & 0 \\end{bmatrix}\\begin{bmatrix} x \\\\ z \\end{bmatrix}$$\n",
    "\n",
    "\n",
    "### Sensitivity and complementary Sensitivity (video 31)\n",
    "https://www.youtube.com/watch?v=hTu36q5yx20&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=31 <br>\n",
    "Goals of feedback:\n",
    "- stability (design)\n",
    "- uncertainty (compensation)\n",
    "- disturtbance (rejection)\n",
    "- noise (attenuation)\n",
    "\n",
    "Denoting the system in tranfer functions allows for easy analysis (sensitivity and complementary sensitivity).\n",
    "- rejection of disturbances \n",
    "- attentuation of noise\n",
    "- references. \n",
    "\n",
    "$$ L = PK $$\n",
    "Sensitivity:\n",
    "$$ S = (I + L)^{-1} $$ \n",
    "Complementary sensitivity\n",
    "$$ T = (I + L)^{-1}L$$\n",
    "then $S + T = I$\n",
    "\n",
    "with the loop diagram with controller, K and system P, L becomes loop PK. \n",
    "Then, $Iy = P_d d + PK (r - y - n) $ which simplifies to: \n",
    "\n",
    "$$ (I + PK)y = PKr + P_dd -PK_n$$\n",
    "$$ y = (I + PK)^{-1}K_r + (I + PK)^{-1}P_dd - (I + PK)^{-1}PK_n $$\n",
    "\n",
    "![](cb_video_31.PNG)\n",
    "\n",
    "### Sensitivity and Complementary Sensitivity (Part 2) (video 32)\n",
    "https://www.youtube.com/watch?v=hEQdr1G5H2w&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=32 <br> \n",
    "Previously saw three parameters; \n",
    "\n",
    "Reference value, r:\n",
    "$(I + PK)^{-1}K_r$ - usually affected by low frequency\n",
    "Disturbance tracking: \n",
    "$(I + PK)^{-1}P_dd$ - usually affected by low frequency\n",
    "\n",
    "Noise:\n",
    "$(I + PK)^{-1}PK_n$ - usually affected by high frequency\n",
    "\n",
    "### Loop shaping (video 33)\n",
    "https://www.youtube.com/watch?v=sfNwLmgK5sE&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=33 <br>\n",
    "\n",
    "Have introduced *sensitivity* and *complementary sensitivity* functions which tell us how our system responds to reference, disturbances and noise inputs. The sensitivity and complementary sensitivity functions can be changed via the loop transfer function, $L = PK$. Bode plots are useful to identify the ideal L. The *sensitivity function*, $S = (I + L)^{-1}$ informs how robust the system is.\n",
    "\n",
    "### Loop Shaping Example for Cruise Control (video 34) \n",
    "https://www.youtube.com/watch?v=fkYcCCujOjc&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=34 <br>\n",
    "\n",
    "Starting with system equation $\\dot{x} = -x + u $ an $y=x$, the system has the following transfer function $\\frac{\\bar{y}(s)}{\\bar{u}(s)} = P(s) = \\frac{1}{s+1}$. Loop is to be designed such that we have have high gain at low frequency to track references and disturbances, low gain at high frequency to reject noise. \n",
    "\n",
    "### Sensitivity and Robustness (video 35)\n",
    "youtube.com/watch?v=7lzH-HnUFZg&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=35 <br> \n",
    "\n",
    "Have focused on what loop transfer functions should to look like for good uncertainty compensation, disturbance rejection and noise attentuation along with shape of Bode plot. Sensitivity, $ S = (I + L)^{-1} $,  gives direct measure of robustness; however this builds on a large body of work including *Nyquist stability critera*. \n",
    "\n",
    "A quick side track on Nyquist stability criteria; given L is in the complex plane, the closer L gets to (-1, 0i) the more unstable a system becomes. What is special about -1? Fundamental systems usually have the transfer function of form $y = \\frac{PK}{1+PK} r$ where r is input, then since $L = PK$ if L = -1 the system becomes undefined and unstable. \n",
    "\n",
    "### Limitations on Robustness (video 36)\n",
    "https://www.youtube.com/watch?v=ReAmUJMb1d8&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=36 <br>\n",
    "Previous lecture reference the instability of the -1 value in complex plane (Nyquist instability equation). This instablility manifests as a peak in the sensitvity function; moreover, the $max_{w}|s| = 1/$ where m is the difference from -1 in complex plane.\n",
    "\n",
    "Things that can cause system (loop transfer function) to blow up? \n",
    "1. Model uncertainty\n",
    "2. Time delay (how fast the system can react)\n",
    "3. Right half plane zeros of P (has to go in wrong direction before system goes in correct direction)\n",
    "\n",
    "The above factors all impact how small the $\\underset{w}{max}|s| = \\frac{1}{m}$ can be. \n",
    "\n",
    "### Cautionary Tale About Inverting the Plant Dynamics (video 37)\n",
    "https://www.youtube.com/watch?v=G9apWx4iaks&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=37 <br>\n",
    "Previous lectures focused on robustness and stability, sometimes you can invert plant transfer function to derive loop transfer function. However, inverting plant, P, to get desired attributes of controller, K.\n",
    "\n",
    "Example:\n",
    "Given plant, P, with system $\\frac{s+10}{s-5}$, then a good controller, K could be $K= \\frac{s-5}{s+10}$ such that$KP = \\frac{s-5}{s+10} \\frac{s+10}{s-5}$. However, issues arise if $P_{true} = \\frac{s+10}{s-5 + \\epsilon}$ then $P_{true}K = \\frac{s-5}{s-5+\\epsilon}$ where the numerator yields a zero at 5 (unobservable state) and denominator yields a pole at $s = 5 -\\epsilon$. The system will be both **unstable** and **unobservable**. \n",
    "\n",
    "Moral of story is if your system has a right hand plane pole do not invert it; even if your plant, P is off by an $\\epsilon$ then the system becomes both **unstable** and **unobservable**.\n",
    "\n",
    "### Control systems with non-minimum phase dynamics (video 38)\n",
    "https://www.youtube.com/watch?v=7GjnvuKeWI8&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=38 <br>\n",
    "A very brief overview on non-minimum phase dynamics for control systems; there's two considerations for non-minimum phase:\n",
    "\n",
    "1. Right half plan zero; when the transfer function, G(s), has a zero in the right-hand plane i.e. consider system with transfer function $\\frac{s-1}{s+5}$. This system has a zero at s = 1. This puts fundamental limits on the controllability of the system.\n",
    "2. Goes in wrong direction first given some into pulse. An aeroplane gaining altitude is an example which needs to shift its centre of mass down first before increasing altitude. This wrong direction is analogous to a 'time-delay' constraint as getting to an optimal output there is an additional trajcectory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1057a156-efdf-468f-a9a6-70bed14668ba",
   "metadata": {},
   "source": [
    "### Control theory and COVID-19 (video 39)\n",
    "https://www.youtube.com/watch?v=BTLZu-1IMcE&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=39 <br>\n",
    "Flattening the COVID-19 infection curve can be framed as a control problem. Covid-19 exhibits many properties of an interesting control system problems, i.e. time delayed responses.\n",
    "To oversimplify, when modelling a disease (i.e. COVID-19) one outcome we want to model is the rate of infections overtime. If rate is too large, then the healthcare system will not cope.\n",
    "\n",
    "Controllers:\n",
    "- Masks\n",
    "- Vaccines\n",
    "- Lockdowns \n",
    "- Knowledge of system\n",
    "- Every person is part of the controller\n",
    "\n",
    "Disease system: \n",
    "- Viral properties\n",
    "- Mutations.\n",
    "\n",
    "The COVID-19 system feedback is defined by the measurments (number of cases); set point is number of infections. Feedback (measurement of numebr of cases) allows us to overcome system uncertainty. Further time delay of being able to measure rates of infections decreases robust performance.\n",
    "\n",
    "Models considered:\n",
    "- Agent based models\n",
    "- Network dynamics models\n",
    "- High dimension non-linear models\n",
    "- SIR models\n",
    "\n",
    "Further zoom in on:\n",
    "- Sensing/measurement issues\n",
    "- Time delays \n",
    "\n",
    "\n",
    "**Control theory is really applied optimisation where you are trying to shape your system output by designing an effective controller/control strategy.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d94ae46-ff83-424d-9768-4bf7ef29d6eb",
   "metadata": {},
   "source": [
    "# Contents:\n",
    "- Videos 2 - 4: First 3 videos focus purely on dynamical systems; control inputs of $U$ matrix is not yet introduced. \n",
    "- Videos 5 - 10: Introduce notion of controlability $u$, proving a system is controllable and the magnitude of controllability a system has. \n",
    "- Videos 11 - 13: Building controllers, and examples of controller in cart pole\n",
    "- Videos 14 - 23: Observability, full state estimation and examples in using Kalman filter (LQE).\n",
    "- Videos 24 - : Introduction to robust control, dealing with uncertainty and disturbances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce02f6f-0c07-46bc-9a75-bc8c7768c3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5431e7ca-9de0-44d1-86fa-e63bb657aa9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_h2",
   "language": "python",
   "name": "venv_h2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
