{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8cfbbfc-4f16-43b9-80ef-4fed61ca4027",
   "metadata": {},
   "source": [
    "##\n",
    "\n",
    "### Control bootcamp overview\n",
    "Contents:\n",
    "    Highlights of modern control theory\n",
    "    design controllers\n",
    "    design sensors (Kalman filters)\n",
    "    major types of optimal control theory\n",
    "    what is easy and hard in control theory\n",
    "    \n",
    "Dynamical systems analysis has been a great way at describing/predicting the evolution of the system. Optimal control builds on dynamical system analysis by allowing for interventions. \n",
    "\n",
    "*Dyanmical systems*: \n",
    "$\\dot{x} = Ax$\n",
    "\n",
    "*Control systems*: \n",
    "$\\dot{x} = Ax + Bu$\n",
    "\n",
    "#### Types of control: \n",
    "Passive control - designed into system upfront/doesn't consume energy\n",
    "Active control - consumes energy\n",
    "    Open loop - preplanned control law, always putting in energy through input signal $u_t$\n",
    "    Closed loop - generally, lower energy than open loop, input signal takes feedback from output signal\n",
    "    \n",
    "*Why feedback (closed loop) over open loop control?*\n",
    "*Uncertainty:* Endogenous system uncertainty in physics model. Allows to deal with uncertainty, an enemy of open loop control. If system deviates from model of system, control laws can adapt. \n",
    "*Instability:* feedback can overcome in instabilities (changes eigenvalues of system), i.e. create new stable points.\n",
    "*Disturbances:* exogenous uncertainties i.e. guest of wind.\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d059f664-c2f6-441b-b0f5-e8461f2862ad",
   "metadata": {},
   "source": [
    "### Nomenclature\n",
    "$u_t$ - Input signal\n",
    "\n",
    "$\\dot{x} = Ax$ - A continous-time linear dynamical system\n",
    "\n",
    "$X_{t+1} = A^{t} X_0$- A discrete-time linear dynamical system\n",
    "\n",
    "Rank deficient - not full column rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c060aa-bf39-4393-a21f-e336ad94912a",
   "metadata": {},
   "source": [
    "### Linear systems (video 2)\n",
    "\n",
    "https://www.youtube.com/watch?v=nyqJJdhReiA&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=2\n",
    "\n",
    "How to analyse and solve linear system\n",
    "HOw to linearise a system and find fixed points\n",
    "What do eigenvalues mean for system\n",
    "\n",
    "The crux of this video is about reducing the complexity of the dynamical system $\\dot{x} = Ax$, through transforming to a *more simple* (linearly independent) eigenvector coordinate system.\n",
    "For what types of systems can we control for; include tests\n",
    "1. Start with linear system; need to solve for $dot{x} = Ax$ but involves exponential of matrix. \n",
    "2. Transfrom into eigenvector coordinates of A. \n",
    "2. Solve differential equations in eigenvector coordinates.\n",
    "3. Taylor series of $e^{At} = T e^{Dt} T^{-1}$, proof below.\\\n",
    "4. Plug eigenvector solution back into *real physical* coordinates, x, $X(t) = Te^{Dt}T^{-1}X(0)$\n",
    "\n",
    "\n",
    "Cornerstone of lecture for controls. \n",
    "$$\\dot{x} = Ax$$\n",
    "Which has solution: \n",
    "$$x(t) = e^At x(0)$$\n",
    "\n",
    "But when A is a matrix how do we take the exponential? Answer; the Taylor series.\n",
    "\n",
    "$e^{At} = I + At + \\frac{A^2t^3}{2!} + \\frac{A^3t^3}{3!} +  ....$\n",
    "\n",
    "The above can be decomposed into eigenvalues and eigenvector coordiante system where $AT = TD \\rightarrow T^-1 A T = D$. Changing these coordinates makes the system easier to solve. Consider mapping to z coordinates where $$x = Tz$$ and $$\\dot{x} = T\\dot{z} = Ax = A Tz  \\rightarrow \\dot{z} = T^{-1} ATz = Dz$$. Where Z is in eigencoordinates (but why?) and D is the diagonal matrice of the eigenvalues which yields $$ \\dot{z} = Dz$$ The above system $ \\dot{z} = Dz$ is simple and known $z(t) = e^Dt z(0)$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Staibility and eigenvalues (video 3) \n",
    "https://www.youtube.com/watch?v=1YMTkELi3tE&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=4\n",
    "\n",
    "Stability is about analying what happens to the system do as time goes to infinity. The crux is anlaysing the eigenvalue matrix, D; if any of these eigenvalues are positive the system 'blows up' and diverges off to infinity. **The system is said to be unstable.** A big part of control theory is that deriving appropriate $u$ control actions to drive eigenvalues to be negative/stable. \n",
    "\n",
    "Generally in physiscs, the linear dynamical system is continuosly evolved. However in practice the system is measured in discrete time. A discrete time system can be modelled as $X_{k+1} = A x_k , x_k = x(\\Delta t)$. In discete time the notion of *stability* is slightly different. In discerte time, state at time t can be derived by simply evolving the system's matrix A, such that: \n",
    "$$ X_1 = A^1 X_0 $$\n",
    "$$ X_2 = A^2 X_0 $$\n",
    "\n",
    "$$ X_N = A^N X_0 $$\n",
    "\n",
    "\n",
    "\n",
    "### Lienarizing Around a Fixed Point (video 4)\n",
    "https://www.youtube.com/watch?v=1YMTkELi3tE&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=4\n",
    "\n",
    "Previous videos have dely with the linear dynamical systems in continuous time. For a non-linear applicatinon, instead of $ \\dot{x} = Ax$, the non-linear form is $\\dot{x} = f(x)$ where $f(x)$ is non-linear but assumed to have fixed points.\n",
    "Fixed point is where the system is stablae and doesn't move i.e. the vertical top or bottom of a pendulum. Albeit, this fixed point is an unstable fixed point as any deviation from this position will cause the system to move away from fixed point.\n",
    "\n",
    "1. Find fixed points such that $f(\\bar{x}) = 0$\n",
    "2. Linearise around x using Jacobian (by taking the partial derivatives of f) \n",
    "\n",
    "i.e. for dynamical system: \n",
    "$$ \\dot{x_1} = f_1(x_1, x_2) = x_1 x_2$$\n",
    "$$ \\dot{x_2} = f_2(x_1, x_2) = x^2_1 + x^2_2$$\n",
    "\n",
    "then:\n",
    "$$ \\frac{Df}{Dx} = \\begin{bmatrix} x_2 & x_1 \\\\ 2x_1 & 2x_2 \\end{bmatrix}$$ \n",
    "\n",
    "\n",
    "Around a fixed point for $\\dot{x} = f(x)$, on a local neighbourhood, expand $f(\\bar{x})$ using a Taylor series. Results in, $ \\dot{x}  = f(\\bar{x}) + \\frac{Df}{Dx}_{\\bar{x}}((x-\\bar{x}) + \\frac{D^2f}{Dx^2}_{\\bar{x}}(x-\\bar{x})^2  $. However, any term above the first order is assumed to be zero. The left over dynamics result in the linearisation of x which yields $\\Delta \\dot{x} = \\frac{Df}{Dx}_{\\bar{x}} \\Delta X \\rightarrow \\Delta \\dot{x} = A \\Delta x$\n",
    "\n",
    "\n",
    "\n",
    "#### Pendulum example\n",
    "Is a ture nonlinear system which has two fixed points and following equations. \n",
    "\n",
    "1. Find state space \n",
    "$\\ddot{\\theta} = -\\frac{g}{L}sin(\\theta)$ which has the following state space equation **Inert image**\n",
    "\n",
    "Then find the fixed points of the state space solution\n",
    "\n",
    "2. Find Jacobian\n",
    "Find matrix of partial differential equations of the system. Substitute in fixed points to Jacobian. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3549ad2e-6c70-4ed0-90da-da7bb96ccc92",
   "metadata": {},
   "source": [
    "### Controlability (video 5)\n",
    "Until this point focus has been on $\\dot{x} = Ax$ absent of $Bu$. A's eigenvalue's were studied to identify which dynamical systems were stable and which weren't. Now control feedback is added to the system, called *controlability*. \n",
    "Starting with $\\dot{x} = Ax - BKx$, where K is the proportionality of feedback control K.\n",
    "\n",
    "What determines if a system is controlable? \n",
    "\n",
    "In industry control problesms the A (dynammical system is fixed) and B (control dynamics)matrices are fixed; only $u$ is controlable.\n",
    "\n",
    "Note: for some complex systems, small number of coupled actuators can control the system. How can we determine if a system can be controled? \n",
    "\n",
    "IFF rank(C) = n then system is controllable, given C = \\[B, AB, A^2B, A^3B, ... , A^{n-1}B\\] (note: A and B are from the control system equation  $\\dot{x} = Ax - BKx$ and n is the dimension of the X. \n",
    "This rule is a binary outcome to determine whether a system is controllable or not. To quantify the amount of controllability of the system, the Singular Value Decomposition of C is taken. The order of the Singular Values is the order in which it the system is easiest to control. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d94ae46-ff83-424d-9768-4bf7ef29d6eb",
   "metadata": {},
   "source": [
    "# Contents:\n",
    "Videoes 2 - 4: First 3 videos focus purely on dynamical systems; control inputs of $U$ matrix is not yet introduced. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce02f6f-0c07-46bc-9a75-bc8c7768c3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5431e7ca-9de0-44d1-86fa-e63bb657aa9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_h2",
   "language": "python",
   "name": "venv_h2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
