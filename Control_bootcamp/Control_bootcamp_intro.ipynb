{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8cfbbfc-4f16-43b9-80ef-4fed61ca4027",
   "metadata": {},
   "source": [
    "##\n",
    "\n",
    "### Control bootcamp overview\n",
    "Contents:\n",
    "    Highlights of modern control theory\n",
    "    design controllers\n",
    "    design sensors (Kalman filters)\n",
    "    major types of optimal control theory\n",
    "    what is easy and hard in control theory\n",
    "    \n",
    "Dynamical systems analysis has been a great way at describing/predicting the evolution of the system. Optimal control builds on dynamical system analysis by allowing for interventions. \n",
    "\n",
    "*Dyanmical systems*: \n",
    "$\\dot{x} = Ax$\n",
    "\n",
    "*Control systems*: \n",
    "$\\dot{x} = Ax + Bu$\n",
    "\n",
    "#### Types of control: \n",
    "Passive control - designed into system upfront/doesn't consume energy\n",
    "Active control - consumes energy\n",
    "    Open loop - preplanned control law, always putting in energy through input signal $u_t$\n",
    "    Closed loop - generally, lower energy than open loop, input signal takes feedback from output signal\n",
    "    \n",
    "*Why feedback (closed loop) over open loop control?*\n",
    "*Uncertainty:* Endogenous system uncertainty in physics model. Allows to deal with uncertainty, an enemy of open loop control. If system deviates from model of system, control laws can adapt. \n",
    "*Instability:* feedback can overcome in instabilities (changes eigenvalues of system), i.e. create new stable points.\n",
    "*Disturbances:* exogenous uncertainties i.e. guest of wind.\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d059f664-c2f6-441b-b0f5-e8461f2862ad",
   "metadata": {},
   "source": [
    "### Nomenclature\n",
    "$u_t$ - Input signal\n",
    "$B$ - input actuation matrix\n",
    "\n",
    "$\\dot{x} = Ax$ - A continous-time linear dynamical system\n",
    "\n",
    "$X_{t+1} = A^{t} X_0$- A discrete-time linear dynamical system\n",
    "\n",
    "Rank deficient - not full column rank\n",
    "\n",
    "Controllability Gramian - magnitude of controllability a system has.\n",
    "\n",
    "*Stability* - A system is said to be *stabilisable* if all of the unstable eigenvectors of A are in controllable subspace. I.e. you may not be able to control all of $\\mathbb{R^n}$ however if all uncontrollable directions have negative eigenvalues (are therefore stable) then system is *stabilisable*.\n",
    "\n",
    "*Reachability* - refers to whether a state can be reached given *controllability*. \n",
    "\n",
    "*Observability* - given system $\\dot{x} = Ax + Bu$, observability is the part of state X that is observable (can obtain data for) such that $y = Cx$. \n",
    "\n",
    "*Estimator* - an estimator is used to estimate the full state x. An example is the Kalman filter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c060aa-bf39-4393-a21f-e336ad94912a",
   "metadata": {},
   "source": [
    "### Linear systems (video 2)\n",
    "\n",
    "https://www.youtube.com/watch?v=nyqJJdhReiA&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=2\n",
    "\n",
    "How to analyse and solve linear system\n",
    "HOw to linearise a system and find fixed points\n",
    "What do eigenvalues mean for system\n",
    "\n",
    "The crux of this video is about reducing the complexity of the dynamical system $\\dot{x} = Ax$, through transforming to a *more simple* (linearly independent) eigenvector coordinate system.\n",
    "For what types of systems can we control for; include tests\n",
    "1. Start with linear system; need to solve for $dot{x} = Ax$ but involves exponential of matrix. \n",
    "2. Transfrom into eigenvector coordinates of A. \n",
    "2. Solve differential equations in eigenvector coordinates.\n",
    "3. Taylor series of $e^{At} = T e^{Dt} T^{-1}$, proof below.\\\n",
    "4. Plug eigenvector solution back into *real physical* coordinates, x, $X(t) = Te^{Dt}T^{-1}X(0)$\n",
    "\n",
    "\n",
    "Cornerstone of lecture for controls. \n",
    "$$\\dot{x} = Ax$$\n",
    "Which has solution: \n",
    "$$x(t) = e^At x(0)$$\n",
    "\n",
    "But when A is a matrix how do we take the exponential? Answer; the Taylor series.\n",
    "\n",
    "$e^{At} = I + At + \\frac{A^2t^3}{2!} + \\frac{A^3t^3}{3!} +  ....$\n",
    "\n",
    "The above can be decomposed into eigenvalues and eigenvector coordiante system where $AT = TD \\rightarrow T^-1 A T = D$. Changing these coordinates makes the system easier to solve. Consider mapping to z coordinates where $$x = Tz$$ and $$\\dot{x} = T\\dot{z} = Ax = A Tz  \\rightarrow \\dot{z} = T^{-1} ATz = Dz$$. Where Z is in eigencoordinates (but why?) and D is the diagonal matrice of the eigenvalues which yields $$ \\dot{z} = Dz$$ The above system $ \\dot{z} = Dz$ is simple and known $z(t) = e^Dt z(0)$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Staibility and eigenvalues (video 3) \n",
    "https://www.youtube.com/watch?v=1YMTkELi3tE&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=4\n",
    "\n",
    "Stability is about analying what happens to the system do as time goes to infinity. The crux is anlaysing the eigenvalue matrix, D; if any of these eigenvalues are positive the system 'blows up' and diverges off to infinity. **The system is said to be unstable.** A big part of control theory is that deriving appropriate $u$ control actions to drive eigenvalues to be negative/stable. \n",
    "\n",
    "Generally in physiscs, the linear dynamical system is continuosly evolved. However in practice the system is measured in discrete time. A discrete time system can be modelled as $X_{k+1} = A x_k , x_k = x(\\Delta t)$. In discete time the notion of *stability* is slightly different. In discerte time, state at time t can be derived by simply evolving the system's matrix A, such that: \n",
    "$$ X_1 = A^1 X_0 $$\n",
    "$$ X_2 = A^2 X_0 $$\n",
    "\n",
    "$$ X_N = A^N X_0 $$\n",
    "\n",
    "\n",
    "\n",
    "### Lienarizing Around a Fixed Point (video 4)\n",
    "https://www.youtube.com/watch?v=1YMTkELi3tE&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=4\n",
    "\n",
    "Previous videos have dely with the linear dynamical systems in continuous time. For a non-linear applicatinon, instead of $ \\dot{x} = Ax$, the non-linear form is $\\dot{x} = f(x)$ where $f(x)$ is non-linear but assumed to have fixed points.\n",
    "Fixed point is where the system is stablae and doesn't move i.e. the vertical top or bottom of a pendulum. Albeit, this fixed point is an unstable fixed point as any deviation from this position will cause the system to move away from fixed point.\n",
    "\n",
    "1. Find fixed points such that $f(\\bar{x}) = 0$\n",
    "2. Linearise around x using Jacobian (by taking the partial derivatives of f) \n",
    "\n",
    "i.e. for dynamical system: \n",
    "$$ \\dot{x_1} = f_1(x_1, x_2) = x_1 x_2$$\n",
    "$$ \\dot{x_2} = f_2(x_1, x_2) = x^2_1 + x^2_2$$\n",
    "\n",
    "then:\n",
    "$$ \\frac{Df}{Dx} = \\begin{bmatrix} x_2 & x_1 \\\\ 2x_1 & 2x_2 \\end{bmatrix}$$ \n",
    "\n",
    "\n",
    "Around a fixed point for $\\dot{x} = f(x)$, on a local neighbourhood, expand $f(\\bar{x})$ using a Taylor series. Results in, $ \\dot{x}  = f(\\bar{x}) + \\frac{Df}{Dx}_{\\bar{x}}((x-\\bar{x}) + \\frac{D^2f}{Dx^2}_{\\bar{x}}(x-\\bar{x})^2  $. However, any term above the first order is assumed to be zero. The left over dynamics result in the linearisation of x which yields $\\Delta \\dot{x} = \\frac{Df}{Dx}_{\\bar{x}} \\Delta X \\rightarrow \\Delta \\dot{x} = A \\Delta x$\n",
    "\n",
    "\n",
    "\n",
    "#### Pendulum example\n",
    "Is a ture nonlinear system which has two fixed points and following equations. \n",
    "\n",
    "1. Find state space \n",
    "$\\ddot{\\theta} = -\\frac{g}{L}sin(\\theta)$ which has the following state space equation **Inert image**\n",
    "\n",
    "Then find the fixed points of the state space solution\n",
    "\n",
    "2. Find Jacobian\n",
    "Find matrix of partial differential equations of the system. Substitute in fixed points to Jacobian. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3549ad2e-6c70-4ed0-90da-da7bb96ccc92",
   "metadata": {},
   "source": [
    "### Controlability (video 5)\n",
    "Until this point focus has been on $\\dot{x} = Ax$ absent of $Bu$. A's eigenvalue's were studied to identify which dynamical systems were stable and which weren't. Now control feedback is added to the system, called *controlability*. \n",
    "Starting with $\\dot{x} = Ax - BKx$, where K is the proportionality of feedback control K.\n",
    "\n",
    "What determines if a system is controlable? \n",
    "\n",
    "In industry control problesms the A (dynammical system is fixed) and B (control dynamics)matrices are fixed; only $u$ is controlable.\n",
    "\n",
    "Note: for some complex systems, small number of coupled actuators can control the system. How can we determine if a system can be controled? \n",
    "\n",
    "IFF rank(C) = n then system is controllable, given C = \\[B, AB, A^2B, A^3B, ... , A^{n-1}B\\] (note: A and B are from the control system equation  $\\dot{x} = Ax - BKx$ and n is the dimension of the X. \n",
    "This rule is a binary outcome to determine whether a system is controllable or not. To quantify the amount of controllability of the system, the Singular Value Decomposition of C is taken. The order of the Singular Values is the order in which it the system is easiest to control. \n",
    "\n",
    "\n",
    "### Controlability Reachability, Eigenvalue Placement (video 6)\n",
    "Reintroduces the *rank deficiency* condition about matrix C, = \\[B, AB, A^2B, A^3B, ... , A^{n-1}B\\] where rank(C) = n where $X \\in \\mathbb{R^n}$\n",
    "\n",
    "Lecture introduces 3 equivalences; \n",
    "1. System is controlable\n",
    "2. Arbitrary eigenvalue (pole) placement where $u = -kX \\rightarrow \\dot{x} = (A -Bk)X$ \n",
    "3. Reachability (full in $\\mathbb{R^n}$  - Reachable set $R_t = { \\eta \\in \\mathbb{R^n} | there is an input u(t) so that x(t) = \\eta}$. More precisely, $R_t \\in \\mathbb{R^n}$\n",
    "\n",
    "## Controlability and Discrete-Time Impulse Response (video 7)\n",
    "https://www.youtube.com/watch?v=tnsWsMwYbEU&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=7\n",
    "\n",
    "Why is the rank deficiency of C sufficient for determining controllability of a system? To give an intuition as to sufficiency consider an *impulse response  in u* at time = 0 for discrete dynamical system $x_{k+1} = Ax_k + Bu_k$ with X(0) = 0 and impulse response u(0) = 1 and u(t) = 0 for t > 0. The below matrix shows how an impulse is propagated through the state space of a solution. The C matrix are these column vectors stacked as columns. The idea being if this stacked matrix is not full rank then variables exist in state stapce, X, such that the control impulse u cannot influence them.\n",
    "\n",
    "$$\\begin{matrix} \n",
    "u_0 = 1 & X_0 = 0 \\\\\n",
    "u_1 = 0 & X_1 = B \\\\\n",
    "u_2 = 0 & X_2 = AB \\\\\n",
    "u_3 = 0 & X_3 = A^2B \\\\\n",
    "... & ... \\\\\n",
    "u_n = 0 & X_n = A^{n-1}B \\\\\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "\n",
    "## Degrees of Controllability and Gramians (video 8)\n",
    "https://www.youtube.com/watch?v=ZNHx62HbKNA&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=8\n",
    "\n",
    "Previously had a binary rule for whether a systme is controllable. Each system has a degree of which it can be controlled; referred to as the *Controllability Gramian*. Eigenvectors of the Gramian matrix have the most amount of controllability, i.e. given a input signal of fixed magnitude, the directions with the largest eigenvalues are affected most. i.e. the Eienvectors/values of Gramian is how far you can get in controllability of a unit input of control. \n",
    "\n",
    "A system dynamical system *with control* yields $X(t) = e^{At} X(0) + \\int_0^te^{A(t - \\tau) B u(\\tau) d \\tau$ where the Gramian (controllability) is given as  $W_t =  \\int_0^te^{At}BB^Te^{A^tt}d \\tau \\in \\mathbb{R^{nxn}}$. IN subsequenet lectures the *Gramian matrix* will be derived; however, Gramian can also be thought of as the *controllability matrix* squared. Taking the SVD of C, SVD(C) ranks the magnitudes of direction of each eigenvector. \n",
    "\n",
    "A system is said to be *stabilisable* if all of the unstable eigenvectors of A are in controllable subspace. I.e. you may not be able to control all of $\\mathbb{R^n}$ however if all uncontrollable directions have negative eigenvalues (are therefore stable) then system is *stabilisable*.\n",
    "\n",
    "\n",
    "## Controllabilty and the PBH Test (video 9): \n",
    "https://www.youtube.com/watch?v=PrfxmkBsYKE&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=9\n",
    "The Popov-Belevitch-Hautus (PBH) test is another test for controllability which is favourable compared to previous rank deficiency tests of C as requires less compute. PBH test assesses if (A, B) is controllable be computing: \n",
    "$$ rank([(A - \\lambda I) B]) = n \\quad \\forall  \\lambda \\in \\mathbb{C}$$\n",
    "\n",
    "There are three criteria to determine $ rank([(A - \\lambda I) B]) = n$ \n",
    "1. When $\\lambda$ is not the eigenvalues then rank (A - \\lambda I) = n since determinant $\\ne$ 0\n",
    "2. B needs to have some component in each eigenvector direction. \n",
    "3. If B is a random vector, then (A,B) will be cotnrollable with high probability. \n",
    "\n",
    "Note: when $rank([(A - \\lambda I) B]) = n$ has m repeated eigenvalues then B must be m dimensions. \n",
    "\n",
    "## Cayley-Hamilton Theorem (video 10): \n",
    "https://www.youtube.com/watch?v=PrfxmkBsYKE&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=10\n",
    "Every matrix A satisfies its own characteristic (eigenvalue) equation. This is important for equivalence for *controlability* and *reachability* which is built on the *Cayley-Hamilton* theorem which states:\n",
    "$$det(A-\\lambda I) = 0 $$\n",
    "$$ \\lambda ^n + a_{n-1} \\lambda ^{n-1} + ... + a_2 \\lambda ^2 + a_1 \\lambda  + a_0 = 0$$\n",
    "and since A satisfies its own characteristic equation, then: \n",
    "$$ A ^n + a_{n-1} A ^{n-1} + ... + a_2 A ^2 + a_1 A  + a_0 = 0 $$\n",
    "$$ A ^n  = a_{n-1} A ^{n-1} + ... + a_2 A ^2 + a_1 A  + a_0 = 0 $$\n",
    "\n",
    "This means $e^{At} = \\phi_0(t)I + \\phi_1(t)A + ... + \\phi_n(t)A^{n-1}$.\n",
    "\n",
    "## Controlabiliy and Reachable with Cayley-Hamilton (video 11)\n",
    "Goal: show that with *controlability*, any state is *reachable*. Note if state, $\\xi \\in \\mathbb{^n}$, is reachable, then $\\xi = \\int^t_0 e^{A(t-\\tau)}Bu(\\tau)d\\tau$ for some $u(\\t)$. Then using the Cayley-Hamilton theorem, the complicated convolution can be avoided to put into form: \n",
    "$$\\xi = \\int^t_0 (\\phi_0(t-\\tau)u(\\tau)IB + \\phi_1(t-\\tau)u(t)AB + ... + \\phi_n-1(t-\\tau)u(t)A^{n-1}B)d\\tau$$\n",
    "$$\\xi = B \\int^t_0 (\\phi_0(t-\\tau)u(\\tau)d\\tau + AB\\int^t_0 \\phi_1(t-\\tau)u(t)d\\tau + ... + A^{n-1}B\\int^t_0\\phi_n-1(t-\\tau)u(t))d\\tau$$\n",
    "\n",
    "$$\n",
    "\\xi =\n",
    "\\begin{bmatrix} \n",
    "B & AB & ... & A^{n-1}B\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} \n",
    "\\int^t_0 (\\phi_0(t-\\tau)u(\\tau)d\\tau \\\\\n",
    "\\int^t_0 \\phi_1(t-\\tau)u(t)d\\tau \\\\\n",
    "... \\\\\n",
    "\\int^t_0\\phi_n-1(t-\\tau)u(t))d\\tau\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "From the *linearisation* of the system by application of Cayley-Hamilton theorem it can be shown that the transformation spans $\\mathbb{R^n}$. Note: there is no unique u(t) that will yield a given state, as there are infinite number of ways to reach given state $\\xi$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c02416-c598-4403-bb7b-0052fba8ab3b",
   "metadata": {},
   "source": [
    "## Inverted pendulum on a cart (video 12)\n",
    "Dynamical system is non-linear and has following characteristics:\n",
    "$$ \\bar{x} = \\begin{bmatrix} x \\\\ \\dot{x} \\\\ \\theta \\\\ \\dot{\\theta} \\end{bmatrix}$$\n",
    "\n",
    "The system has two fixed points; $(free, 0, 0, 0) or (free, 0,\\pi, 0)$ for downward and upward fixed points respectively. Each point is then linearised.\n",
    "\n",
    "*Desigining a controller*. Code is presented which covers; \n",
    "1. Compute eigenvalues of A to identify stable points.\n",
    "2. Determine rank of matrix to determine *controlability*. \n",
    "3. Set values of prortional controller K such that eigenvalues of $(A-B*K)$ are stable and equal to eigenvalue vector defined (i.e. all negative). Note there is sweet spot, such that the eigenvalues reach a solution fast but not so fast that the control breaks. This optimal trade off is solved through application of Linear Quadratic Regulators which balance how fast you get to a stable state vs the control energy it takes to get there.\n",
    "\n",
    "## Linear Quadratic Regulator Control for the Inverted Pendulum on a Cart (video 13)\n",
    "Previously, eigenvalues for the (A-BK) matrix used for feedback was guessed. However, given a certain cost function, an optimal set of eigenvalues exists. Linear Quadratic Regulation is a method to calculate this optima. Given, the objective function: \n",
    "$$ J = \\int_0^\\infty (x^TQx + u^TRu)dt$$\n",
    "\n",
    "LQR refers to:\n",
    "- Linear - linear in feedback of K \n",
    "- Quadratic - quadratic in cost function\n",
    "- Regulator - means will stabilise system\n",
    "\n",
    "## Motivation for Full-State Estimation (video 15)\n",
    "https://www.youtube.com/watch?v=LTNMf8X21cY&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=15\n",
    "With LQR full control of the system was available, however, in real life full state isn't alway accessible. Given a dynamical system, $\\dot{x} = Ax + Bu, \\quad x \\in \\mathbb{R^n}$, the observability of a system is given by $y = Cx, \\quad y \\in \\mathbb{R^p}$ sucht that p << n. Whereas *controlability* is steering towards state, *observability* is can I *observe* state X from measurement $y(t)$. Since for control, not all states are always available and an *observer* can be created.\n",
    "\n",
    "### Observability\n",
    "An estimator is used to estimate the full state x. An example is the Kalman filter. Observability and controlability have the same linear algebra i.e. the same rank tests apply. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d94ae46-ff83-424d-9768-4bf7ef29d6eb",
   "metadata": {},
   "source": [
    "# Contents:\n",
    "- Videos 2 - 4: First 3 videos focus purely on dynamical systems; control inputs of $U$ matrix is not yet introduced. \n",
    "- Videos 5 - 10: Introduce notion of controlability $u$, proving a system is controllable and the magnitude of controllability a system has. \n",
    "- Videos 11 - :Building controllers, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce02f6f-0c07-46bc-9a75-bc8c7768c3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5431e7ca-9de0-44d1-86fa-e63bb657aa9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_h2",
   "language": "python",
   "name": "venv_h2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
