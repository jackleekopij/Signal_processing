{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8cfbbfc-4f16-43b9-80ef-4fed61ca4027",
   "metadata": {},
   "source": [
    "##\n",
    "\n",
    "### Control bootcamp overview\n",
    "Contents:\n",
    "    Highlights of modern control theory\n",
    "    design controllers\n",
    "    design sensors (Kalman filters)\n",
    "    major types of optimal control theory\n",
    "    what is easy and hard in control theory\n",
    "    \n",
    "Dynamical systems analysis has been a great way at describing/predicting the evolution of the system. Optimal control builds on dynamical system analysis by allowing for interventions. \n",
    "\n",
    "*Dyanmical systems*: \n",
    "$\\dot{x} = Ax$\n",
    "\n",
    "*Control systems*: \n",
    "$\\dot{x} = Ax + Bu$\n",
    "\n",
    "#### Types of control: \n",
    "Passive control - designed into system upfront/doesn't consume energy\n",
    "Active control - consumes energy\n",
    "    Open loop - preplanned control law, always putting in energy through input signal $u_t$\n",
    "    Closed loop - generally, lower energy than open loop, input signal takes feedback from output signal\n",
    "    \n",
    "*Why feedback (closed loop) over open loop control?*\n",
    "*Uncertainty:* Endogenous system uncertainty in physics model. Allows to deal with uncertainty, an enemy of open loop control. If system deviates from model of system, control laws can adapt. \n",
    "*Instability:* feedback can overcome in instabilities (changes eigenvalues of system), i.e. create new stable points.\n",
    "*Disturbances:* exogenous uncertainties i.e. guest of wind.\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d059f664-c2f6-441b-b0f5-e8461f2862ad",
   "metadata": {},
   "source": [
    "### Nomenclature\n",
    "$u_t$ - Input signal\n",
    "$B$ - input actuation matrix\n",
    "\n",
    "$\\dot{x} = Ax$ - A continous-time linear dynamical system\n",
    "\n",
    "$X_{t+1} = A^{t} X_0$- A discrete-time linear dynamical system\n",
    "\n",
    "Rank deficient - not full column rank\n",
    "\n",
    "Controllability Gramian - magnitude of controllability a system has. Usually calculated by an SVD approach to on 'rank deficiency' calculation matrix. \n",
    "\n",
    "*Stability* - A system is said to be *stabilisable* if all of the unstable eigenvectors of A are in controllable subspace. I.e. you may not be able to control all of $\\mathbb{R^n}$ however if all uncontrollable directions have negative eigenvalues (are therefore stable) then system is *stabilisable*.\n",
    "\n",
    "*Reachability* - refers to whether a state can be reached given *controllability*. \n",
    "\n",
    "*Observability* - given system $\\dot{x} = Ax + Bu$, observability is the part of state X that is observable (can obtain data for) such that $y = Cx$. \n",
    "\n",
    "*Estimator* - an estimator is used to estimate the full state x. An example is the Kalman filter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c060aa-bf39-4393-a21f-e336ad94912a",
   "metadata": {},
   "source": [
    "### Linear systems (video 2)\n",
    "\n",
    "https://www.youtube.com/watch?v=nyqJJdhReiA&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=2\n",
    "\n",
    "How to analyse and solve linear system\n",
    "HOw to linearise a system and find fixed points\n",
    "What do eigenvalues mean for system\n",
    "\n",
    "The crux of this video is about reducing the complexity of the dynamical system $\\dot{x} = Ax$, through transforming to a *more simple* (linearly independent) eigenvector coordinate system.\n",
    "For what types of systems can we control for; include tests\n",
    "1. Start with linear system; need to solve for $dot{x} = Ax$ but involves exponential of matrix. \n",
    "2. Transfrom into eigenvector coordinates of A. \n",
    "2. Solve differential equations in eigenvector coordinates.\n",
    "3. Taylor series of $e^{At} = T e^{Dt} T^{-1}$, proof below.\\\n",
    "4. Plug eigenvector solution back into *real physical* coordinates, x, $X(t) = Te^{Dt}T^{-1}X(0)$\n",
    "\n",
    "\n",
    "Cornerstone of lecture for controls. \n",
    "$$\\dot{x} = Ax$$\n",
    "Which has solution: \n",
    "$$x(t) = e^At x(0)$$\n",
    "\n",
    "But when A is a matrix how do we take the exponential? Answer; the Taylor series.\n",
    "\n",
    "$e^{At} = I + At + \\frac{A^2t^3}{2!} + \\frac{A^3t^3}{3!} +  ....$\n",
    "\n",
    "The above can be decomposed into eigenvalues and eigenvector coordiante system where $AT = TD \\rightarrow T^-1 A T = D$. Changing these coordinates makes the system easier to solve. Consider mapping to z coordinates where $$x = Tz$$ and $$\\dot{x} = T\\dot{z} = Ax = A Tz  \\rightarrow \\dot{z} = T^{-1} ATz = Dz$$. Where Z is in eigencoordinates (but why?) and D is the diagonal matrice of the eigenvalues which yields $$ \\dot{z} = Dz$$ The above system $ \\dot{z} = Dz$ is simple and known $z(t) = e^Dt z(0)$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Staibility and eigenvalues (video 3) \n",
    "https://www.youtube.com/watch?v=1YMTkELi3tE&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=4\n",
    "\n",
    "Stability is about analying what happens to the system do as time goes to infinity. The crux is anlaysing the eigenvalue matrix, D; if any of these eigenvalues are positive the system 'blows up' and diverges off to infinity. **The system is said to be unstable.** A big part of control theory is that deriving appropriate $u$ control actions to drive eigenvalues to be negative/stable. \n",
    "\n",
    "Generally in physiscs, the linear dynamical system is continuosly evolved. However in practice the system is measured in discrete time. A discrete time system can be modelled as $X_{k+1} = A x_k , x_k = x(\\Delta t)$. In discete time the notion of *stability* is slightly different. In discerte time, state at time t can be derived by simply evolving the system's matrix A, such that: \n",
    "$$ X_1 = A^1 X_0 $$\n",
    "$$ X_2 = A^2 X_0 $$\n",
    "\n",
    "$$ X_N = A^N X_0 $$\n",
    "\n",
    "\n",
    "\n",
    "### Lienarizing Around a Fixed Point (video 4)\n",
    "https://www.youtube.com/watch?v=1YMTkELi3tE&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=4\n",
    "\n",
    "Previous videos have dely with the linear dynamical systems in continuous time. For a non-linear applicatinon, instead of $ \\dot{x} = Ax$, the non-linear form is $\\dot{x} = f(x)$ where $f(x)$ is non-linear but assumed to have fixed points.\n",
    "Fixed point is where the system is stablae and doesn't move i.e. the vertical top or bottom of a pendulum. Albeit, this fixed point is an unstable fixed point as any deviation from this position will cause the system to move away from fixed point.\n",
    "\n",
    "1. Find fixed points such that $f(\\bar{x}) = 0$\n",
    "2. Linearise around x using Jacobian (by taking the partial derivatives of f) \n",
    "\n",
    "i.e. for dynamical system: \n",
    "$$ \\dot{x_1} = f_1(x_1, x_2) = x_1 x_2$$\n",
    "$$ \\dot{x_2} = f_2(x_1, x_2) = x^2_1 + x^2_2$$\n",
    "\n",
    "then:\n",
    "$$ \\frac{Df}{Dx} = \\begin{bmatrix} x_2 & x_1 \\\\ 2x_1 & 2x_2 \\end{bmatrix}$$ \n",
    "\n",
    "\n",
    "Around a fixed point for $\\dot{x} = f(x)$, on a local neighbourhood, expand $f(\\bar{x})$ using a Taylor series. Results in, $ \\dot{x}  = f(\\bar{x}) + \\frac{Df}{Dx}_{\\bar{x}}((x-\\bar{x}) + \\frac{D^2f}{Dx^2}_{\\bar{x}}(x-\\bar{x})^2  $. However, any term above the first order is assumed to be zero. The left over dynamics result in the linearisation of x which yields $\\Delta \\dot{x} = \\frac{Df}{Dx}_{\\bar{x}} \\Delta X \\rightarrow \\Delta \\dot{x} = A \\Delta x$\n",
    "\n",
    "\n",
    "\n",
    "#### Pendulum example\n",
    "Is a ture nonlinear system which has two fixed points and following equations. \n",
    "\n",
    "1. Find state space \n",
    "$\\ddot{\\theta} = -\\frac{g}{L}sin(\\theta)$ which has the following state space equation **Inert image**\n",
    "\n",
    "Then find the fixed points of the state space solution\n",
    "\n",
    "2. Find Jacobian\n",
    "Find matrix of partial differential equations of the system. Substitute in fixed points to Jacobian. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3549ad2e-6c70-4ed0-90da-da7bb96ccc92",
   "metadata": {},
   "source": [
    "### Controlability (video 5)\n",
    "Until this point focus has been on $\\dot{x} = Ax$ absent of $Bu$. A's eigenvalue's were studied to identify which dynamical systems were stable and which weren't. Now control feedback is added to the system, called *controlability*. \n",
    "Starting with $\\dot{x} = Ax - BKx$, where K is the proportionality of feedback control K.\n",
    "\n",
    "What determines if a system is controlable? \n",
    "\n",
    "In industry control problesms the A (dynammical system is fixed) and B (control dynamics)matrices are fixed; only $u$ is controlable.\n",
    "\n",
    "Note: for some complex systems, small number of coupled actuators can control the system. How can we determine if a system can be controled? \n",
    "\n",
    "IFF rank(C) = n then system is controllable, given C = \\[B, AB, A^2B, A^3B, ... , A^{n-1}B\\] (note: A and B are from the control system equation  $\\dot{x} = Ax - BKx$ and n is the dimension of the X. \n",
    "This rule is a binary outcome to determine whether a system is controllable or not. To quantify the amount of controllability of the system, the Singular Value Decomposition of C is taken. The order of the Singular Values is the order in which it the system is easiest to control. \n",
    "\n",
    "\n",
    "### Controlability Reachability, Eigenvalue Placement (video 6)\n",
    "Reintroduces the *rank deficiency* condition about matrix C, = \\[B, AB, A^2B, A^3B, ... , A^{n-1}B\\] where rank(C) = n where $X \\in \\mathbb{R^n}$\n",
    "\n",
    "Lecture introduces 3 equivalences; \n",
    "1. System is controlable\n",
    "2. Arbitrary eigenvalue (pole) placement where $u = -kX \\rightarrow \\dot{x} = (A -Bk)X$ \n",
    "3. Reachability (full in $\\mathbb{R^n}$  - Reachable set $R_t = { \\eta \\in \\mathbb{R^n} | there is an input u(t) so that x(t) = \\eta}$. More precisely, $R_t \\in \\mathbb{R^n}$\n",
    "\n",
    "## Controlability and Discrete-Time Impulse Response (video 7)\n",
    "https://www.youtube.com/watch?v=tnsWsMwYbEU&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=7\n",
    "\n",
    "Why is the rank deficiency of C sufficient for determining controllability of a system? To give an intuition as to sufficiency consider an *impulse response  in u* at time = 0 for discrete dynamical system $x_{k+1} = Ax_k + Bu_k$ with X(0) = 0 and impulse response u(0) = 1 and u(t) = 0 for t > 0. The below matrix shows how an impulse is propagated through the state space of a solution. The C matrix are these column vectors stacked as columns. The idea being if this stacked matrix is not full rank then variables exist in state stapce, X, such that the control impulse u cannot influence them.\n",
    "\n",
    "$$\\begin{matrix} \n",
    "u_0 = 1 & X_0 = 0 \\\\\n",
    "u_1 = 0 & X_1 = B \\\\\n",
    "u_2 = 0 & X_2 = AB \\\\\n",
    "u_3 = 0 & X_3 = A^2B \\\\\n",
    "... & ... \\\\\n",
    "u_n = 0 & X_n = A^{n-1}B \\\\\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "\n",
    "## Degrees of Controllability and Gramians (video 8)\n",
    "https://www.youtube.com/watch?v=ZNHx62HbKNA&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=8\n",
    "\n",
    "Previously had a binary rule for whether a systme is controllable. Each system has a degree of which it can be controlled; referred to as the *Controllability Gramian*. Eigenvectors of the Gramian matrix have the most amount of controllability, i.e. given a input signal of fixed magnitude, the directions with the largest eigenvalues are affected most. i.e. the Eienvectors/values of Gramian is how far you can get in controllability of a unit input of control. \n",
    "\n",
    "A system dynamical system *with control* yields $X(t) = e^{At} X(0) + \\int_0^te^{A(t - \\tau) B u(\\tau) d \\tau$ where the Gramian (controllability) is given as  $W_t =  \\int_0^te^{At}BB^Te^{A^tt}d \\tau \\in \\mathbb{R^{nxn}}$. IN subsequenet lectures the *Gramian matrix* will be derived; however, Gramian can also be thought of as the *controllability matrix* squared. Taking the SVD of C, SVD(C) ranks the magnitudes of direction of each eigenvector. \n",
    "\n",
    "A system is said to be *stabilisable* if all of the unstable eigenvectors of A are in controllable subspace. I.e. you may not be able to control all of $\\mathbb{R^n}$ however if all uncontrollable directions have negative eigenvalues (are therefore stable) then system is *stabilisable*.\n",
    "\n",
    "\n",
    "## Controllabilty and the PBH Test (video 9): \n",
    "https://www.youtube.com/watch?v=PrfxmkBsYKE&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=9\n",
    "The Popov-Belevitch-Hautus (PBH) test is another test for controllability which is favourable compared to previous rank deficiency tests of C as requires less compute. PBH test assesses if (A, B) is controllable be computing: \n",
    "$$ rank([(A - \\lambda I) B]) = n \\quad \\forall  \\lambda \\in \\mathbb{C}$$\n",
    "\n",
    "There are three criteria to determine $ rank([(A - \\lambda I) B]) = n$ \n",
    "1. When $\\lambda$ is not the eigenvalues then rank (A - \\lambda I) = n since determinant $\\ne$ 0\n",
    "2. B needs to have some component in each eigenvector direction. \n",
    "3. If B is a random vector, then (A,B) will be cotnrollable with high probability. \n",
    "\n",
    "Note: when $rank([(A - \\lambda I) B]) = n$ has m repeated eigenvalues then B must be m dimensions. \n",
    "\n",
    "## Cayley-Hamilton Theorem (video 10): \n",
    "https://www.youtube.com/watch?v=PrfxmkBsYKE&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=10\n",
    "Every matrix A satisfies its own characteristic (eigenvalue) equation. This is important for equivalence for *controlability* and *reachability* which is built on the *Cayley-Hamilton* theorem which states:\n",
    "$$det(A-\\lambda I) = 0 $$\n",
    "$$ \\lambda ^n + a_{n-1} \\lambda ^{n-1} + ... + a_2 \\lambda ^2 + a_1 \\lambda  + a_0 = 0$$\n",
    "and since A satisfies its own characteristic equation, then: \n",
    "$$ A ^n + a_{n-1} A ^{n-1} + ... + a_2 A ^2 + a_1 A  + a_0 = 0 $$\n",
    "$$ A ^n  = a_{n-1} A ^{n-1} + ... + a_2 A ^2 + a_1 A  + a_0 = 0 $$\n",
    "\n",
    "This means $e^{At} = \\phi_0(t)I + \\phi_1(t)A + ... + \\phi_n(t)A^{n-1}$.\n",
    "\n",
    "## Controlabiliy and Reachable with Cayley-Hamilton (video 11)\n",
    "Goal: show that with *controlability*, any state is *reachable*. Note if state, $\\xi \\in \\mathbb{^n}$, is reachable, then $\\xi = \\int^t_0 e^{A(t-\\tau)}Bu(\\tau)d\\tau$ for some $u(\\t)$. Then using the Cayley-Hamilton theorem, the complicated convolution can be avoided to put into form: \n",
    "$$\\xi = \\int^t_0 (\\phi_0(t-\\tau)u(\\tau)IB + \\phi_1(t-\\tau)u(t)AB + ... + \\phi_n-1(t-\\tau)u(t)A^{n-1}B)d\\tau$$\n",
    "$$\\xi = B \\int^t_0 (\\phi_0(t-\\tau)u(\\tau)d\\tau + AB\\int^t_0 \\phi_1(t-\\tau)u(t)d\\tau + ... + A^{n-1}B\\int^t_0\\phi_n-1(t-\\tau)u(t))d\\tau$$\n",
    "\n",
    "$$\n",
    "\\xi =\n",
    "\\begin{bmatrix} \n",
    "B & AB & ... & A^{n-1}B\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} \n",
    "\\int^t_0 (\\phi_0(t-\\tau)u(\\tau)d\\tau \\\\\n",
    "\\int^t_0 \\phi_1(t-\\tau)u(t)d\\tau \\\\\n",
    "... \\\\\n",
    "\\int^t_0\\phi_n-1(t-\\tau)u(t))d\\tau\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "From the *linearisation* of the system by application of Cayley-Hamilton theorem it can be shown that the transformation spans $\\mathbb{R^n}$. Note: there is no unique u(t) that will yield a given state, as there are infinite number of ways to reach given state $\\xi$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c02416-c598-4403-bb7b-0052fba8ab3b",
   "metadata": {},
   "source": [
    "## Inverted pendulum on a cart (video 12)\n",
    "Dynamical system is non-linear and has following characteristics:\n",
    "$$ \\bar{x} = \\begin{bmatrix} x \\\\ \\dot{x} \\\\ \\theta \\\\ \\dot{\\theta} \\end{bmatrix}$$\n",
    "\n",
    "The system has two fixed points; $(free, 0, 0, 0) or (free, 0,\\pi, 0)$ for downward and upward fixed points respectively. Each point is then linearised.\n",
    "\n",
    "*Desigining a controller*. Code is presented which covers; \n",
    "1. Compute eigenvalues of A to identify stable points.\n",
    "2. Determine rank of matrix to determine *controlability*. \n",
    "3. Set values of prortional controller K such that eigenvalues of $(A-B*K)$ are stable and equal to eigenvalue vector defined (i.e. all negative). Note there is sweet spot, such that the eigenvalues reach a solution fast but not so fast that the control breaks. This optimal trade off is solved through application of Linear Quadratic Regulators which balance how fast you get to a stable state vs the control energy it takes to get there.\n",
    "\n",
    "## Linear Quadratic Regulator Control for the Inverted Pendulum on a Cart (video 13)\n",
    "Previously, eigenvalues for the (A-BK) matrix used for feedback was guessed. However, given a certain cost function, an optimal set of eigenvalues exists. Linear Quadratic Regulation is a method to calculate this optima. Given, the objective function: \n",
    "$$ J = \\int_0^\\infty (x^TQx + u^TRu)dt$$\n",
    "\n",
    "LQR refers to:\n",
    "- Linear - linear in feedback of K \n",
    "- Quadratic - quadratic in cost function\n",
    "- Regulator - means will stabilise system\n",
    "\n",
    "### Motivation for Full-State Estimation (video 15)\n",
    "https://www.youtube.com/watch?v=LTNMf8X21cY&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=15<br>\n",
    "With LQR full control of the system was available, however, in real life full state isn't alway accessible. Given a dynamical system, $\\dot{x} = Ax + Bu, \\quad x \\in \\mathbb{R^n}$, the observability of a system is given by $y = Cx, \\quad y \\in \\mathbb{R^p}$ sucht that p << n. Whereas *controlability* is steering towards state, *observability* is can I *observe* state X from measurement $y(t)$. Since for control, not all states are always available and an *observer* can be created.\n",
    "\n",
    "### Observability (video 16)\n",
    "https://www.youtube.com/watch?v=LTNMf8X21cY&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=16 <br>\n",
    "An estimator is used to estimate the full state x. An example is the Kalman filter. Observability and controlability have the same linear algebra i.e. the same rank tests apply. Mathematically, they are the same problem Gramians apply etc.\n",
    "\n",
    "### Full State Estimation (video 17)\n",
    "https://www.youtube.com/watch?v=LTNMf8X21cY&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=17 <br>\n",
    "The Kalman filter is a method to derive full state estimations, required for input into Linear Quadratic Controllers. Starting with the dynamical system: \n",
    "$$ \\dot{x} = Ax + Bu $$\n",
    "$$ y = Cx$$ \n",
    "Then the estimator for the full states, the *Kalman filter*, is a dynamical system in itself such that $\\hat{x} = f(u,y)$. Then the estimate $\\frac{d}{dt}\\hat{x} = A \\hat{x} + Bu + K_f(y - \\hat{x})$ given that $\\hat{y} = C\\hat{x}$. Rearranging $\\frac{d}{dt}\\hat{x}$ yields: \n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{d}{dt}\\hat{x} &= A\\hat{x} + Bu + K_fy - K_fC\\hat{x} \\\\\n",
    "&= (A - K_fC)\\hat{x} + \\begin{bmatrix} B & K_f \\end{bmatrix}\\begin{bmatrix} u \\\\ y \\end{bmatrix}\n",
    "\\end{align}\n",
    "$$ \n",
    "\n",
    "Finally, the full state estimate error, $epsilon = x - \\hat{x}$ that has the following dynamical system for error. \n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{d}{dt}\\epsilon &= \\frac{d}{dt}x - \\frac{d}{dt}\\hat{x} = Ax + Bu - A\\hat{x} + K_fC\\hat{x} - K_fy  - Bu \\\\\n",
    "&= A(x-\\hat{x}) - K_fC(x - \\hat{x}) \\quad \\text{since 'Bu's cancel out} \\\\\n",
    "&= (A - K_fC)\\epsilon \\\\ \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In the last equation, if observable than place eigenvalues by choosing optimal K.\n",
    "![](video_17.PNG)\n",
    "\n",
    "### Kalman Filters (video 18)\n",
    "https://www.youtube.com/watch?v=LTNMf8X21cY&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=17 <br>\n",
    "\n",
    "Kalman filter has components: \n",
    "- $W_d$ - Gaussian (system disturbance) with zero mean and defined variance, $V_d$.\n",
    "- $V_d$ - Variance\n",
    "- $W_n$ - Gaussian (measurement noise) with zero mean and defined variance, $V_n$.\n",
    "- $V_n$ - Variance\n",
    "\n",
    "such that: \n",
    "$$ \\dot{x} = Ax + Bu + w_d$$\n",
    "$$ y = Cx + w_n$$ \n",
    "\n",
    "The Kalman filter balances $\\dot{x} = (A-k_fC)\\epsilon$ and optimises $J = E((x - \\hat{x})^T(x-\\hat{x}))$ given the estimates for $W_d$ and $W_n$. \n",
    "\n",
    "### Observability in Example (video 19)\n",
    "https://www.youtube.com/watch?v=XBI_hQRqMvM&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=19 <br>\n",
    "Previously have looked at dynamical system of equations $$ \\dot{x} = Ax + Bu + w_d$$ $$ y = Cx + w_n$$ then testing observability matrix (A,C) and check for rank deficiency. The most popular method for full state estimation is the *Kalman filter*. Applying observabilty to the cart problem, start with hypothesis that $\\begin{bmatrix} 1 & 0 & 0 & 0 \\end{bmatrix}$ is enough for observability. Remember, that observabilty matrix is  $\\begin{bmatrix} C \\\\ CA \\\\ CA^2 \\\\ CA^3 \\end{bmatrix}$ which is full rank. \n",
    "\n",
    "### Observability Example - Part 2 (video 20)\n",
    "https://www.youtube.com/watch?v=DLytfA10RR8&list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&index=20 <br>\n",
    "What about if the cart position, x, is not important (translational invariant) can an obvervable system be found? IF X is removed than the matrix (A,C) becomes observable which informs that all variables $\\dot{x}, \\, \\theta \\, \\& \\, \\dot{\\theta}$ are dependent and can be backed out from a single observation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cb8778-727b-43a8-90ab-12e8aa80bd92",
   "metadata": {},
   "source": [
    "### Kalman Filter Example\n",
    "Focus in this lecture is continued on the cart pole problem and then further focuses on fixed point in the downward position. First, implement Kalman filter to derive estimate of the full states, $\\hat{x}$ to overcome observability problem. The balance between variance in the system $V_d$ and measurement $V_n$ which are tuning knobs and tells us how the Kalman filter is going balance the model of the system against the measurements.\n",
    "\n",
    "There are a multiple ways to build a Kalman filter; note the LQE equation can solve the Kalman filter however so can the LQR if matrices are transposed.\n",
    "\n",
    "1. An example would create *true simulated data* from a deterministic model dyanmical systems model; \n",
    "2. then create a Kalman filter for deterministic system. \n",
    "3. Inject noise to the *true simulated data* (which uses the system's true dynamics) to form *simulated + noise* data\n",
    "4. Run state estimation on *simulated + noise* data\n",
    "5. Plot resulting outputs for all variables in state.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d94ae46-ff83-424d-9768-4bf7ef29d6eb",
   "metadata": {},
   "source": [
    "# Contents:\n",
    "- Videos 2 - 4: First 3 videos focus purely on dynamical systems; control inputs of $U$ matrix is not yet introduced. \n",
    "- Videos 5 - 10: Introduce notion of controlability $u$, proving a system is controllable and the magnitude of controllability a system has. \n",
    "- Videos 11 - :Building controllers, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce02f6f-0c07-46bc-9a75-bc8c7768c3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5431e7ca-9de0-44d1-86fa-e63bb657aa9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_h2",
   "language": "python",
   "name": "venv_h2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
